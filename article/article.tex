\documentclass[a4paper]{article}

\usepackage[english,russian]{babel}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=blue
}
\usepackage{float}
\usepackage[utf8]{inputenc}
\usepackage[14pt]{extsizes}
\usepackage{physics}
\usepackage{graphicx}
\graphicspath{{../misc/}}
\usepackage{setspace,amsmath}
\usepackage[left=20mm, top=15mm, right=15mm, bottom=15mm, nohead, footskip=10mm]{geometry} 

\usepackage[backend=biber]{biblatex}
\addbibresource{lit.bib}

\begin{document} 

\begin{center}
    \hfill \break
    ФЕДЕРАЛЬНОЕ ГОСУДАРСТВЕННОЕ БЮДЖЕТНОЕ ОБРАЗОВАТЕЛЬНОЕ 

    УЧРЕЖДЕНИЕ ВЫСШЕГО ОБРАЗОВАНИЯ

    «МОСКОВСКИЙ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ

    имени М.В.ЛОМОНОСОВА»

    \hfill \break
    \normalsize{ФИЗИЧЕСКИЙ ФАКУЛЬТЕТ}\\
    \hfill \break
    \normalsize{КАФЕДРА ОБЩЕЙ ФИЗИКИ И МОЛЕКУЛЯРНОЙ ЭЛЕКТРОНИКИ}\\
    \hfill\break
    \hfill \break
    \normalsize{БАКАЛАВРСКАЯ РАБОТА}\\
    \hfill \break
    \large\textbf{«МОДЕЛИРОВАНИЕ РАСПОЗНАВАНИЯ ОБРАЗОВ НА ОСНОВЕ ИСПУЛЬСНЫХ НЕЙРОННЫХ СЕТЕЙ С КОНКУРЕНЦИЕЙ ЛОКАЛЬНЫХ РЕЦЕПТИВНЫХ ПОЛЕЙ»}\\
    \hfill \break

\end{center}

\begin{flushright}

    Выполнил студент:

    406 группа

    Гафни Д.

    $\underset{\text{подпись студента}}{\underline{\hspace{0.3\textwidth}}}$

    \hfill\break

    Научный руководитель:

    Королёва А.В.

    $\underset{\text{подпись научного руководителя}}{\underline{\hspace{0.3\textwidth}}}$
    
    \hfill\break
    
    Научный консультант:

    Дёмин В.А.

    $\underset{\text{подпись научного консультанта}}{\underline{\hspace{0.3\textwidth}}}$

\end{flushright}


Допущена к защите

Зав.кафедрой $\underset{\text{подпись зав.кафедрой}}{\underline{\hspace{0.3\textwidth}}}$
\hfill\break
\hfill\break
\begin{center}

Москва

\hfill\break
2020
\end{center}



\thispagestyle{empty} 

\tableofcontents

\clearpage

\section{Введение}
Импульсные (спайковые) нейронные сети (СНС) являются перспективным нейроморфным алгоритмом, биологически корректно моделируя взаимодействия нейронов мозга. Наибольший интерес СНС представляют для решения задач в реальном времени (принятие решений, распознавание образов), так как могут быть реализованы на специализированном вычислительно- и энергоэффективном мемристорном нейрочипе, так как 

Стандартные методы обучения весов связей, применяющиеся в формальных нейронных сетях (метод обратного распространения ошибки) не представляется возможным применять к СНС из-за их дискретной и распределенной во времени природы. Таким образом, исследование алгоритмов обучения СНС представляется важной задачей.

\subsection{Мотивация}
\paragraph{Недостатки формальных нейронных сетей}
Современные формальные нейронные сети отлично справляются со многими задачами машинного обучения \cite{pmlr-v28-wan13}. Однако их обучение - трудоемкий процесс, требующий больших вычислительных ресурсов. Обычно обучение ведется на десятках и сотнях тысячах примеров и может занимать месяцы. Как само обучение, так и последующее применение формальных нейросетевых алгоритмов далеки от эффективности. Это связано как с физически раздельным хранением значений весов и активаций нейронов, так и с самими вычислениями, которые носят тензорный характер. Современные процессоры не оптимизированы для подобных вычислений. Гораздо лучше процессоров для этих задач подходят GPU - архитектуры, изначально созданные для работы с компьютерной графикой, а потому лучше подходяшие для тензорных вычислений, однако и они не дают желаемого результата. Например, типичное время распознавание лица современными алгоритмами - 200-300 мс.

\subsection{Постановка задачи}
В данной работе:

\begin{enumerate}
 \item Изучается влияние обучения связей конкуренции \cite{MaxActiv1} \cite{MaxActiv2} между нейронами на точность распознавания образов в задаче классификации рукописных изображений цифр (MNIST) при обучении без учителя для архитектуры локально соединенной сети (Locally Connected Spiking Neural Network, LCSNN) \cite{saunders2019locally}
 
 \item Проводится сравнение этой архитектуры со сверточной сетью (Convolution Spiking Neural Network, CSNN) и полносвязной сетью (Fully Connected Spiking Neural Network, FCSNN).

\end{enumerate}

\clearpage

\section{Спайковые нейронные сети}
Спайковая нейронная сеть - модель нейронной сети, которая состоит из отдельных нейронов и связей между ними. Каждый нейрон имеет свой виртуальный потенциал, а каждая связь имеет некоторый вес. Нейроны обмениваются дискретными электрическими сигналами (спайками), имеющими очень короткую ($ \approx ~1$ мс) длительность. Влияние входящих спайков на потенциал нейрона определяется значением веса межнейронной связи. При накоплении потенциала, превышающего определенный порог активации, нейрон сам испускает спайк, а после сбрасывает свой напряжение до некоторого уровня релаксации. При запуске сети активность некоторых входных нейронов задается определенным образом, после чего проводится симуляция на протяжении некоторого времени ($\approx ~250$ мс), много большего длительности спайка.


\subsection{Преимущества спайковых нейронных сетей}
В отличие от формальных, спайковые нейронные сети:

\begin{itemize}
 \item могут быть реализованы на специализированном сверхэффективном нейроморфном процессоре
 \item биологически корректно моделируют взаимодействия нейронов
\end{itemize}

Ней
*Почему биологическая корректность это хорошо*

\subsection{Модели нейронов спайковой нейронной сети}
Реальный нейрон мозга является очень сложным объектом, поведение которого до сих пор не до конца изучено. Для спайковых нейронных сетей используются упрощенные модели нейронов. Перечислим некоторые из них.

\subsubsection{Интегратор с утечкой и адаптивным порогом}
В данной работе используется модель адаптивного ``Интегрировать-и-сработать'' нейрона с утечкой (Adaptive Leaky Integrate-And-Fire, ALIF). В этой модели динамика потенциала задается следующим уравнением:

\begin{equation} \label{ALIF_voltage_dynamics}
 \tau_v \dv{v(t)}{t} = -v(t) + v_{rest} + I(t) \text{,}
\end{equation} где $I(t)$ - ток, накопившийся в нейроне к моменту времени $t$, $v_{rest}$ - уровень релаксации, $\tau_v$ - временная константа симуляции.\\
Таким образом, потенциал нейрона сам по себе стремится вернуться в состояние релаксации, так как если $I(t) = 0$ (нет входящих спайков) и $v(t) = v_{rest}$, то производная $\dv{v(t)}{t} = 0$, то есть потенциал нейрона будет оставаться постоянным на уровне $v_{rest}$.\\
Порог активации $v_{thresh}$ у ALIF нейрона не является константой, а немного повышается при каждом спайке, релаксируя затем к своему начальному значению. Динамика порога активации задается следующими уравнениями:

\begin{equation} \label{ALIF_thresh}
 v_{thresh} = \theta_0 + \theta(t) \text{,}
\end{equation} где $\theta_0$ - начальный порог активации, $\theta(t)$ - адаптивная добавка, которая вычисляется из условия\\

\begin{equation} \label{ALIF_thresh_dynamics}
 \tau_v \dv{\theta(t)}{t} = -\theta(t)
\end{equation}\\
Таким образом, порог активации нейрона сам по себе стремится вернуться к начальному значению, так как при $\theta(t) = \theta_0$, то производная $\dv{\theta(t)}{t} = 0$, то есть порог активации нейрона будет оставаться постоянным на уровне $\theta_0$.\\
После испускания каждого спайка порог активации повышается на $\theta_{plus}$.

\begin{center}
\begin{figure}[H] 
 \includegraphics[width=\textwidth,keepaspectratio=true]{voltage_ru.pdf}
 \caption{Динамика потенциала нейрона. Красными точками отмечены моменты времени, когда нейрон испускает спайк и сбрасывает свой потенциал до уровня релаксации.}
\end{figure}
\end{center}

\subsection{Архитектуры спайковых нейронных сетей}
Архитектуры

\subsection{Алгоритмы обучения спайковых нейронных сетей}

STDP - Spike Timing Dependent Plasticity - биологически инспирированное правило обучения без учителя.
\begin{equation} 
\Delta w =
 \begin{cases}
 A_+ \cdot e^{- \frac{t_{pre} - t_{post}}{\tau_+}}, t_{pre} - t_{post} > 0\\
 A_- \cdot e^{- \frac{t_{pre} - t_{post}}{\tau_-}}, t_{pre} - t_{post} < 0
 \end{cases}
\end{equation}

\begin{figure}[h] \label{STDP}
\begin{center}
 \includegraphics[,
 width=\textwidth,keepaspectratio=true]{STDP_ru.pdf}
 
 \caption{Правило STDP. График зависимости изменения веса от разности времени регистрации пост- и пре- спайков.}
\end{center}
\end{figure}

\subsection{Современные реализации спайковых нейронных}
Современные реализации

\clearpage

\section{Моделирование обучения спайковой нейронной сети с конкуренцией локальных рецептивных полей}

\subsection{Описание задачи классификации}
Описание задачи

\subsection{Особенности архитектуры}
Эта нейросетевая архитектура вдохновлена строением зрительной коры мозга. В отличие от сверточной сети, ее нейроны не имеют общих весов, которые потому и называются локальными. На иллюстрации ниже показано строение локально соединенной сети.

\begin{figure}[H]
    \centering
    \def\svgwidth{\columnwidth}
    \input{../misc/LCSNN.pdf_tex}
    \label{LCSNN}
    \caption{Схема архитектуры LCSNN}
\end{figure}

% \begin{figure}
%  \includegraphics{LCSNN.pdf}
% \end{figure}



Нейроны, имеющие общие рецептивные поля дополнительно соединяются связями конкуренции. Такие связи имеют отрицательные веса, а значит, негативно влияют на активность. Заметим, что нейроны, не имеющие общего рецептивного поля (а значит, реагирующие на разные области изображения) не конкурируют между собой.\\
LCSNN отличаются большой скоростью обучения. Через несколько тысяч итераций точность распознавания выходит на плато насыщения, после чего уже не возрастает.

\begin{center}
\begin{figure}[H]
 \includegraphics[width=\textwidth,keepaspectratio=true]{LCSNN_learning_rate_ru.pdf}
 \caption{Скорость обучения LCSNN}
\end{figure}
\end{center}

\begin{figure}
\begin{center}
 \includegraphics[,
 width=\textwidth,keepaspectratio=true]{weights_XY.pdf}
 \label{weights_XY}
 \caption{Веса XY слоя после обучения}
\end{center}
\end{figure}

\subsection{Сравнение эффективности операции свертки и локального рецептивного поля}
Результаты экспериментов с различными архитектурами

\begin{center}
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
{Архитектура} & {Фильтры} & {Ядро} & {Веса} & {Нейроны} & {Точность} & {Погрешность}\\
\hline
{LCSNN} & {100} & {12} & {449100} & {900} & {0.8752} & {0.0090}\\
\hline
{LCSNN} & {100} & {8} & {798400} & {1600} & {0.8285} & {0.0021}\\
\hline
{LCSNN} & {25} & {12} & {95400} & {225} & {0.7939} & {0.0038}\\
\hline
{LCSNN} & {25} & {8} & {169600} & {400} & {0.7360} & {0.0103}\\
\hline
{CSNN} & {100} & {8} & {11350} & {1600} & {0.7736} & {0.0188}\\
\hline
{CSNN} & {25} & {12} & {3900} & {225} & {0.6577} & {0.0067}\\
\hline
{CSNN} & {25} & {8} & {1900} & {400} & {0.5807} & {0.0117}\\
\hline
{FCSNN} & {100} & {20} & {44950} & {100} & {0.7340} & {0.0866}\\
\hline
\end{tabular}
\end{center}

\subsection{Обучение связей конкуренции спайковой нейронной сети}


\subsection{Выводы}
Выводы

\clearpage

\section{Заключение}
Было обнаружено, что обучение связей конкуренции нейронов, имеющих общие рецептивные поля, позволяет добиться большей точности распознавания изображений по сравнению с той же архитектурой, но с необучаемыми связями конкуренции. Также было показано, что LCSNN имеет преимущество над CSNN как по скорости обучения, так и по точности распознавания. Таким образом, локально соединенная сеть – перспективная нейросетевая архитектура, превосходящая классические алгоритмы в точности распознавания изображений при обучении без учителя, и подходит для реализации на вычислительном мемристорном нейрочипе.

\clearpage

\section{Благодарности}
Благодарности

\printbibliography

\end{document}  
