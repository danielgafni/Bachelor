{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T00:40:50.651488Z",
     "start_time": "2019-10-09T00:40:50.637524Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "from time import time as t\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from bindsnet.network import Network, load\n",
    "from bindsnet.learning import PostPre, WeightDependentPostPre\n",
    "from bindsnet.network.monitors import Monitor, NetworkMonitor\n",
    "from bindsnet.network.nodes import AdaptiveLIFNodes, Input\n",
    "from bindsnet.network.topology import LocalConnection, Connection\n",
    "from bindsnet.analysis.plotting import (\n",
    "    plot_input,\n",
    "    plot_spikes,\n",
    "    plot_conv2d_weights,\n",
    "    plot_voltages,\n",
    "    plot_spikes_display\n",
    ")\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from LC_SNN import LC_SNN\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and encoding MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T20:48:54.603112Z",
     "start_time": "2019-10-08T20:48:54.558232Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "time_max = 30\n",
    "dt = 1\n",
    "intensity = 127.5\n",
    "\n",
    "train_dataset = MNIST(\n",
    "    PoissonEncoder(time=time_max, dt=dt),\n",
    "    None,\n",
    "    \"MNIST\",\n",
    "    download=False,\n",
    "    train=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T20:49:01.086786Z",
     "start_time": "2019-10-08T20:48:56.719451Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters \n",
    "n_filters = 25\n",
    "kernel_size = 12\n",
    "stride = 4 \n",
    "padding = 0\n",
    "conv_size = int((28 - kernel_size + 2 * padding) / stride) + 1\n",
    "per_class = int((n_filters * conv_size * conv_size) / 10)\n",
    "tc_trace = 20.  # grid search check\n",
    "tc_decay = 20.\n",
    "thresh = -52\n",
    "refrac = 5\n",
    "\n",
    "wmin = 0\n",
    "wmax = 1\n",
    "\n",
    "# Network\n",
    "network = Network(learning=True)\n",
    "GlobalMonitor = NetworkMonitor(network, state_vars=('v', 's', 'w'))\n",
    "\n",
    "\n",
    "input_layer = Input(n=784, shape=(1, 28, 28), traces=True)\n",
    "\n",
    "output_layer = AdaptiveLIFNodes(\n",
    "    n=n_filters * conv_size * conv_size,\n",
    "    shape=(n_filters, conv_size, conv_size),\n",
    "    traces=True,\n",
    "    thres=thresh,\n",
    "    trace_tc=tc_trace,\n",
    "    tc_decay=tc_decay,\n",
    "    theta_plus=0.05,\n",
    "    tc_theta_decay=1e6)\n",
    "\n",
    "\n",
    "connection_XY = LocalConnection(\n",
    "    input_layer,\n",
    "    output_layer,\n",
    "    n_filters=n_filters,\n",
    "    kernel_size=kernel_size,\n",
    "    stride=stride,\n",
    "    update_rule=PostPre,\n",
    "    norm=1/2, #1/(kernel_size ** 2),#0.4 * kernel_size ** 2,  # norm constant - check\n",
    "    nu=[1e-4, 1e-2],\n",
    "    wmin=wmin,\n",
    "    wmax=wmax)\n",
    "\n",
    "# competitive connections\n",
    "w = torch.zeros(n_filters, conv_size, conv_size, n_filters, conv_size, conv_size)\n",
    "for fltr1 in range(n_filters):\n",
    "    for fltr2 in range(n_filters):\n",
    "        if fltr1 != fltr2:\n",
    "            # change\n",
    "            for i in range(conv_size):\n",
    "                for j in range(conv_size):\n",
    "                    w[fltr1, i, j, fltr2, i, j] = -100.0\n",
    "                    \n",
    "connection_YY = Connection(output_layer, output_layer, w=w)\n",
    "\n",
    "network.add_layer(input_layer, name='X')\n",
    "network.add_layer(output_layer, name='Y')\n",
    "\n",
    "network.add_connection(connection_XY, source='X', target='Y')\n",
    "network.add_connection(connection_YY, source='Y', target='Y')\n",
    "\n",
    "network.add_monitor(GlobalMonitor, name='Network')\n",
    "\n",
    "spikes = {}\n",
    "for layer in set(network.layers):\n",
    "    spikes[layer] = Monitor(network.layers[layer], state_vars=[\"s\"], time=time_max)\n",
    "    network.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)\n",
    "    print('GlobalMonitor.state_vars:', GlobalMonitor.state_vars)\n",
    "\n",
    "voltages = {}\n",
    "for layer in set(network.layers) - {\"X\"}:\n",
    "    voltages[layer] = Monitor(network.layers[layer], state_vars=[\"v\"], time=time_max)\n",
    "    network.add_monitor(voltages[layer], name=\"%s_voltages\" % layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:25:41.843382Z",
     "start_time": "2019-10-07T07:25:41.816599Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize = False\n",
    "n_train = 1\n",
    "for epoch in range(n_train):\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    for batch in tqdm(train_dataloader):\n",
    "        inpts = {\"X\": batch[\"encoded_image\"]}\n",
    "        inpts = {\"X\": batch[\"encoded_image\"].transpose(0, 1)}\n",
    "\n",
    "        network.run(inpts=inpts, time=time_max, input_time_dim=1)\n",
    "    network.reset_()  # Reset state variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T12:57:23.616273Z",
     "start_time": "2019-09-27T12:57:21.973Z"
    }
   },
   "outputs": [],
   "source": [
    "network.save(f'network_{str(datetime.datetime.today())}'[:-7].replace(' ', '_').replace(':', '-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locking network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T12:57:23.618755Z",
     "start_time": "2019-09-27T12:57:21.980Z"
    }
   },
   "outputs": [],
   "source": [
    "network.train(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T12:57:23.620747Z",
     "start_time": "2019-09-27T12:57:21.985Z"
    }
   },
   "outputs": [],
   "source": [
    "network = load('default', learning=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T20:49:20.439994Z",
     "start_time": "2019-10-08T20:49:19.192321Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "for whatever, batch in tqdm(list(zip(range(5), test_dataloader))):\n",
    "    cmap = plt.cm.jet\n",
    "    #Processing\n",
    "    inpts = {\"X\": batch[\"encoded_image\"].transpose(0, 1)}\n",
    "    label = batch[\"label\"]\n",
    "    network.run(inpts=inpts, time=time_max, input_time_dim=1)\n",
    "\n",
    "    #Visualization\n",
    "    # Optionally plot various simulation information.\n",
    "    inpt_axes = None\n",
    "    inpt_ims = None\n",
    "    spike_ims = None\n",
    "    spike_axes = None\n",
    "    weights1_im = None\n",
    "    voltage_ims = None\n",
    "    voltage_axes = None\n",
    "    image = batch[\"image\"].view(28, 28)\n",
    "\n",
    "    inpt = inpts[\"X\"].view(time_max, 784).sum(0).view(28, 28)\n",
    "    weights_XY = connection_XY.w\n",
    "    weights_YY = connection_YY.w\n",
    "\n",
    "    _spikes = {\n",
    "        \"X\": spikes[\"X\"].get(\"s\").view(time_max, -1),\n",
    "        \"Y\": spikes[\"Y\"].get(\"s\").view(time_max, -1),\n",
    "    }\n",
    "    _voltages = {\"Y\": voltages[\"Y\"].get(\"v\").view(time_max, -1)}\n",
    "\n",
    "    inpt_axes, inpt_ims = plot_input(\n",
    "        image, inpt, label=label, axes=inpt_axes, ims=inpt_ims\n",
    "    )\n",
    "    spike_ims, spike_axes = plot_spikes_display(_spikes, ims=spike_ims, axes=spike_axes)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 10))\n",
    "    weights_XY = weights_XY.reshape(28, 28, -1)\n",
    "    weights_to_display = torch.zeros(0, 28*25)\n",
    "    i = 0\n",
    "    while i < 625:\n",
    "        for j in range(25):\n",
    "            weights_to_display_row = torch.zeros(28, 0)\n",
    "            for k in range(25):\n",
    "                weights_to_display_row = torch.cat((weights_to_display_row, weights_XY[:, :, i]), dim=1)\n",
    "                i += 1\n",
    "            weights_to_display = torch.cat((weights_to_display, weights_to_display_row), dim=0)\n",
    "    im1 = ax1.imshow(weights_to_display.numpy(), cmap=cmap)\n",
    "    im2 = ax2.imshow(weights_YY.reshape(5*5*25, 5*5*25).numpy(), cmap=cmap)\n",
    "    f.colorbar(im1, ax=ax1)\n",
    "    f.colorbar(im2, ax=ax2)\n",
    "    ax1.set_title('XY weights')\n",
    "    ax2.set_title('YY weights')\n",
    "    f.show()\n",
    "    voltage_ims, voltage_axes = plot_voltages(\n",
    "        _voltages, ims=voltage_ims, axes=voltage_axes\n",
    "    )\n",
    "    \n",
    "network.reset_()  # Reset state variables\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch for best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T00:27:57.188355Z",
     "start_time": "2019-10-09T00:27:52.109929Z"
    }
   },
   "outputs": [],
   "source": [
    "def gridsearch(n_norm=2, n_comp=2, n_iter=100):\n",
    "    norms  = np.linspace(0.1, 0.4, n_norm)\n",
    "    comp_weights = np.linspace(-70, -13, n_comp)\n",
    "    accs = torch.zeros(n_norm, n_comp)\n",
    "    max_acc = 0\n",
    "    best_norm = 0\n",
    "    best_comp_weight = 0\n",
    "    for i, norm in enumerate(norms):\n",
    "        for j, competitive_weight in enumerate(comp_weights):\n",
    "            clear_output(wait=True)\n",
    "            print(f'Current parameters: norm={norm}, comp_weight={competitive_weight}')\n",
    "            net = LC_SNN(norm=norm, competitive_weight=competitive_weight)\n",
    "            net.train(n_iter=n_iter)\n",
    "            net.network.save(f'gridsearch//network_norm={norm}_comp={competitive_weight}_n_iter={n_iter}')\n",
    "            acc = net.accuracy(n_iter)\n",
    "            accs[i, j] = acc\n",
    "            if acc > max_acc:\n",
    "                max_acc = acc\n",
    "                best_norm = norm\n",
    "                best_comp_weght = competitive_weight\n",
    "    torch.save(accs, f'gridsearch//accs_n_norm={n_norm}_n_comp={n_comp}_n_iter=n_iter')\n",
    "    return max_acc, best_norm, competitive_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T00:31:13.246963Z",
     "start_time": "2019-10-09T00:28:22.342289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating top classes for each neuron...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:13<00:00, 13.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:14<00:00, 13.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.104"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch(n_norm=5, n_comp=10, n_iter=60000)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
