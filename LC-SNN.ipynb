{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T16:18:29.081045Z",
     "start_time": "2019-10-10T16:18:29.070142Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "from time import time as t\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from bindsnet.network import Network, load\n",
    "from bindsnet.learning import PostPre, WeightDependentPostPre\n",
    "from bindsnet.network.monitors import Monitor, NetworkMonitor\n",
    "from bindsnet.network.nodes import AdaptiveLIFNodes, Input\n",
    "from bindsnet.network.topology import LocalConnection, Connection\n",
    "from bindsnet.analysis.plotting import (\n",
    "    plot_input,\n",
    "    plot_spikes,\n",
    "    plot_conv2d_weights,\n",
    "    plot_voltages,\n",
    ")\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from LC_SNN import LC_SNN\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and encoding MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T07:53:20.586497Z",
     "start_time": "2019-10-09T07:53:20.129132Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "time_max = 30\n",
    "dt = 1\n",
    "intensity = 127.5\n",
    "\n",
    "train_dataset = MNIST(\n",
    "    PoissonEncoder(time=time_max, dt=dt),\n",
    "    None,\n",
    "    \"MNIST\",\n",
    "    download=False,\n",
    "    train=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T14:05:17.975172Z",
     "start_time": "2019-10-09T14:05:14.034697Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters \n",
    "n_filters = 25\n",
    "kernel_size = 12\n",
    "stride = 4 \n",
    "padding = 0\n",
    "conv_size = int((28 - kernel_size + 2 * padding) / stride) + 1\n",
    "per_class = int((n_filters * conv_size * conv_size) / 10)\n",
    "tc_trace = 20.  # grid search check\n",
    "tc_decay = 20.\n",
    "thresh = -52\n",
    "refrac = 5\n",
    "\n",
    "wmin = 0\n",
    "wmax = 1\n",
    "\n",
    "# Network\n",
    "network = Network(learning=True)\n",
    "GlobalMonitor = NetworkMonitor(network, state_vars=('v', 's', 'w'))\n",
    "\n",
    "\n",
    "input_layer = Input(n=784, shape=(1, 28, 28), traces=True)\n",
    "\n",
    "output_layer = AdaptiveLIFNodes(\n",
    "    n=n_filters * conv_size * conv_size,\n",
    "    shape=(n_filters, conv_size, conv_size),\n",
    "    traces=True,\n",
    "    thres=thresh,\n",
    "    trace_tc=tc_trace,\n",
    "    tc_decay=tc_decay,\n",
    "    theta_plus=0.05,\n",
    "    tc_theta_decay=1e6)\n",
    "\n",
    "\n",
    "connection_XY = LocalConnection(\n",
    "    input_layer,\n",
    "    output_layer,\n",
    "    n_filters=n_filters,\n",
    "    kernel_size=kernel_size,\n",
    "    stride=stride,\n",
    "    update_rule=PostPre,\n",
    "    norm=1/2, #1/(kernel_size ** 2),#0.4 * kernel_size ** 2,  # norm constant - check\n",
    "    nu=[1e-4, 1e-2],\n",
    "    wmin=wmin,\n",
    "    wmax=wmax)\n",
    "\n",
    "# competitive connections\n",
    "w = torch.zeros(n_filters, conv_size, conv_size, n_filters, conv_size, conv_size)\n",
    "for fltr1 in range(n_filters):\n",
    "    for fltr2 in range(n_filters):\n",
    "        if fltr1 != fltr2:\n",
    "            # change\n",
    "            for i in range(conv_size):\n",
    "                for j in range(conv_size):\n",
    "                    w[fltr1, i, j, fltr2, i, j] = -100.0\n",
    "                    \n",
    "connection_YY = Connection(output_layer, output_layer, w=w)\n",
    "\n",
    "network.add_layer(input_layer, name='X')\n",
    "network.add_layer(output_layer, name='Y')\n",
    "\n",
    "network.add_connection(connection_XY, source='X', target='Y')\n",
    "network.add_connection(connection_YY, source='Y', target='Y')\n",
    "\n",
    "network.add_monitor(GlobalMonitor, name='Network')\n",
    "\n",
    "spikes = {}\n",
    "for layer in set(network.layers):\n",
    "    spikes[layer] = Monitor(network.layers[layer], state_vars=[\"s\"], time=time_max)\n",
    "    network.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)\n",
    "    print('GlobalMonitor.state_vars:', GlobalMonitor.state_vars)\n",
    "\n",
    "voltages = {}\n",
    "for layer in set(network.layers) - {\"X\"}:\n",
    "    voltages[layer] = Monitor(network.layers[layer], state_vars=[\"v\"], time=time_max)\n",
    "    network.add_monitor(voltages[layer], name=\"%s_voltages\" % layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:25:41.843382Z",
     "start_time": "2019-10-07T07:25:41.816599Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize = False\n",
    "n_train = 1\n",
    "for epoch in range(n_train):\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    for batch in tqdm(train_dataloader):\n",
    "        inpts = {\"X\": batch[\"encoded_image\"]}\n",
    "        inpts = {\"X\": batch[\"encoded_image\"].transpose(0, 1)}\n",
    "\n",
    "        network.run(inpts=inpts, time=time_max, input_time_dim=1)\n",
    "    network.reset_()  # Reset state variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T12:57:23.616273Z",
     "start_time": "2019-09-27T12:57:21.973Z"
    }
   },
   "outputs": [],
   "source": [
    "network.save(f'network_{str(datetime.datetime.today())}'[:-7].replace(' ', '_').replace(':', '-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locking network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T12:57:23.618755Z",
     "start_time": "2019-09-27T12:57:21.980Z"
    }
   },
   "outputs": [],
   "source": [
    "network.train(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T12:57:23.620747Z",
     "start_time": "2019-09-27T12:57:21.985Z"
    }
   },
   "outputs": [],
   "source": [
    "network = load('default', learning=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T20:49:20.439994Z",
     "start_time": "2019-10-08T20:49:19.192321Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "for whatever, batch in tqdm(list(zip(range(5), test_dataloader))):\n",
    "    cmap = plt.cm.jet\n",
    "    #Processing\n",
    "    inpts = {\"X\": batch[\"encoded_image\"].transpose(0, 1)}\n",
    "    label = batch[\"label\"]\n",
    "    network.run(inpts=inpts, time=time_max, input_time_dim=1)\n",
    "\n",
    "    #Visualization\n",
    "    # Optionally plot various simulation information.\n",
    "    inpt_axes = None\n",
    "    inpt_ims = None\n",
    "    spike_ims = None\n",
    "    spike_axes = None\n",
    "    weights1_im = None\n",
    "    voltage_ims = None\n",
    "    voltage_axes = None\n",
    "    image = batch[\"image\"].view(28, 28)\n",
    "\n",
    "    inpt = inpts[\"X\"].view(time_max, 784).sum(0).view(28, 28)\n",
    "    weights_XY = connection_XY.w\n",
    "    weights_YY = connection_YY.w\n",
    "\n",
    "    _spikes = {\n",
    "        \"X\": spikes[\"X\"].get(\"s\").view(time_max, -1),\n",
    "        \"Y\": spikes[\"Y\"].get(\"s\").view(time_max, -1),\n",
    "    }\n",
    "    _voltages = {\"Y\": voltages[\"Y\"].get(\"v\").view(time_max, -1)}\n",
    "\n",
    "    inpt_axes, inpt_ims = plot_input(\n",
    "        image, inpt, label=label, axes=inpt_axes, ims=inpt_ims\n",
    "    )\n",
    "    spike_ims, spike_axes = plot_spikes_display(_spikes, ims=spike_ims, axes=spike_axes)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 10))\n",
    "    weights_XY = weights_XY.reshape(28, 28, -1)\n",
    "    weights_to_display = torch.zeros(0, 28*25)\n",
    "    i = 0\n",
    "    while i < 625:\n",
    "        for j in range(25):\n",
    "            weights_to_display_row = torch.zeros(28, 0)\n",
    "            for k in range(25):\n",
    "                weights_to_display_row = torch.cat((weights_to_display_row, weights_XY[:, :, i]), dim=1)\n",
    "                i += 1\n",
    "            weights_to_display = torch.cat((weights_to_display, weights_to_display_row), dim=0)\n",
    "    im1 = ax1.imshow(weights_to_display.numpy(), cmap=cmap)\n",
    "    im2 = ax2.imshow(weights_YY.reshape(5*5*25, 5*5*25).numpy(), cmap=cmap)\n",
    "    f.colorbar(im1, ax=ax1)\n",
    "    f.colorbar(im2, ax=ax2)\n",
    "    ax1.set_title('XY weights')\n",
    "    ax2.set_title('YY weights')\n",
    "    f.show()\n",
    "    voltage_ims, voltage_axes = plot_voltages(\n",
    "        _voltages, ims=voltage_ims, axes=voltage_axes\n",
    "    )\n",
    "    \n",
    "network.reset_()  # Reset state variables\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch for best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T00:27:57.188355Z",
     "start_time": "2019-10-09T00:27:52.109929Z"
    }
   },
   "outputs": [],
   "source": [
    "def gridsearch(n_norm=2, n_comp=2, n_iter=100):\n",
    "    norms  = np.linspace(0.1, 0.4, n_norm)\n",
    "    comp_weights = np.linspace(-70, -13, n_comp)\n",
    "    accs = torch.zeros(n_norm, n_comp)\n",
    "    max_acc = 0\n",
    "    best_norm = 0\n",
    "    best_comp_weight = 0\n",
    "    for i, norm in enumerate(norms):\n",
    "        for j, competitive_weight in enumerate(comp_weights):\n",
    "            clear_output(wait=True)\n",
    "            print(f'Current parameters: norm={norm}, comp_weight={competitive_weight}')\n",
    "            net = LC_SNN(norm=norm, competitive_weight=competitive_weight)\n",
    "            net.train(n_iter=n_iter)\n",
    "            net.network.save(f'gridsearch//network_norm={norm}_comp={competitive_weight}_n_iter={n_iter}')\n",
    "            acc = net.accuracy(n_iter)\n",
    "            accs[i, j] = acc\n",
    "            if acc > max_acc:\n",
    "                max_acc = acc\n",
    "                best_norm = norm\n",
    "                best_comp_weght = competitive_weight\n",
    "    torch.save(accs, f'gridsearch//accs_n_norm={n_norm}_n_comp={n_comp}_n_iter=n_iter')\n",
    "    return max_acc, best_norm, competitive_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T00:31:13.246963Z",
     "start_time": "2019-10-09T00:28:22.342289Z"
    }
   },
   "outputs": [],
   "source": [
    "gridsearch(n_norm=5, n_comp=10, n_iter=60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T14:05:21.924241Z",
     "start_time": "2019-10-09T14:05:21.919254Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:48:55.939118Z",
     "start_time": "2019-10-09T09:48:55.929151Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "from LC_SNN import LC_SNN\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "class Wtf:\n",
    "    def __init__(self, norm=1, competitive_weight=1, n_iter=1):\n",
    "        print('initing')\n",
    "    def fit(self, X, y, n_iter):\n",
    "        print('fitting')\n",
    "    def score(self, X, y):\n",
    "        print('predicting')\n",
    "        return np.random.random()\n",
    "    def get_params(self, **args):\n",
    "        return {'norm': 1,\n",
    "                'competitive_weight':1,\n",
    "                'n_iter':1\n",
    "               }\n",
    "    def set_params(self, norm, competitive_weight, n_iter):\n",
    "        return Wtf(norm=norm, competitive_weight=competitive_weight, n_iter=n_iter)\n",
    "    def __repr__(self):\n",
    "        return f'WTF class' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T10:05:22.163146Z",
     "start_time": "2019-10-09T10:05:22.108288Z"
    }
   },
   "outputs": [],
   "source": [
    "time_max = 30\n",
    "dt = 1\n",
    "intensity = 127.5\n",
    "\n",
    "train_dataset = MNIST(\n",
    "    PoissonEncoder(time=time_max, dt=dt),\n",
    "    None,\n",
    "    \"MNIST\",\n",
    "    download=False,\n",
    "    train=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=1, shuffle=True)\n",
    "for batch in test_dataloader:\n",
    "    print(batch['label'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T10:00:16.510189Z",
     "start_time": "2019-10-09T10:00:16.118220Z"
    }
   },
   "outputs": [],
   "source": [
    "data= pd.read_csv('encoded_MNIST.csv', sep='\\t')\n",
    "X_numpy, y_numpy = data['encoded_image'].values, data['label'].values\n",
    "X = []\n",
    "y = []\n",
    "for elem in zip(X_numpy, y_numpy):\n",
    "    X.append(torch.tensor(elem[0]))\n",
    "    y.append(str(elem[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T14:08:03.569404Z",
     "start_time": "2019-10-09T14:08:03.563393Z"
    }
   },
   "outputs": [],
   "source": [
    "stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T14:09:08.646511Z",
     "start_time": "2019-10-09T14:09:08.558666Z"
    }
   },
   "outputs": [],
   "source": [
    "kernel_size = (12, 12)\n",
    "conv_size = (5, 5)\n",
    "stride = (4, 4)\n",
    "shape = [625, 625]\n",
    "locations = torch.zeros(\n",
    "            kernel_size[0], kernel_size[1], conv_size[0], conv_size[1]\n",
    "        ).long()\n",
    "for c1 in range(conv_size[0]):\n",
    "    for c2 in range(conv_size[0]):\n",
    "        for k1 in range(kernel_size[0]):\n",
    "            for k2 in range(kernel_size[0]):\n",
    "                location = (\n",
    "                    c1 * stride[0] * shape[0]\n",
    "                    + c2 * stride[0]\n",
    "                    + k1 * shape[0]\n",
    "                    + k2\n",
    "                )\n",
    "                locations[k1, k2, c1, c2] = location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T14:09:54.520859Z",
     "start_time": "2019-10-09T14:09:54.508866Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T13:31:39.904100Z",
     "start_time": "2019-10-09T13:31:39.828331Z"
    }
   },
   "outputs": [],
   "source": [
    "from LC_SNN import LC_SNN\n",
    "net = LC_SNN(load=True)\n",
    "net.load('network')\n",
    "weights = torch.tensor(net.weights_XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T14:02:08.253518Z",
     "start_time": "2019-10-09T14:02:06.751479Z"
    }
   },
   "outputs": [],
   "source": [
    "weights_formatted = torch.zeros(25*12, 25*12)\n",
    "for i in range(25):\n",
    "    for j in range(25):\n",
    "        for k1 in range(12):\n",
    "            for k2 in range(12):\n",
    "                weights_formatted[12*i + k1, 12*j + k2] = weights[28*i + k1 + 4*((i//5)//5), 28*i + k2 + (2*((j//5)//5))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T14:02:10.639081Z",
     "start_time": "2019-10-09T14:02:08.362175Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15), dpi=200)\n",
    "plt.imshow(weights_formatted.numpy(), cmap='YlOrBr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T13:32:20.607805Z",
     "start_time": "2019-10-09T13:32:19.979471Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(weights.numpy(), cmap='YlOrBr')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T16:18:40.046570Z",
     "start_time": "2019-10-10T16:18:34.987069Z"
    }
   },
   "outputs": [],
   "source": [
    "est = LC_SNN()\n",
    "est.load('network')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T20:01:36.028866Z",
     "start_time": "2019-10-10T16:19:17.876392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating top classes for each neuron...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [3:38:03<00:00, 15.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[7, 0, 3, ..., 8, 6, 6],\n",
       "        [0, 8, 2, ..., 2, 0, 0],\n",
       "        [8, 5, 8, ..., 5, 2, 2],\n",
       "        ...,\n",
       "        [None, 4, 1, ..., 4, 9, 8],\n",
       "        [1, 1, None, ..., None, None, None],\n",
       "        [6, None, 7, ..., 7, 1, 7]], dtype=object),\n",
       " tensor([[1.8756e-02, 6.5153e-02, 5.9230e-03,  ..., 5.9230e-03, 6.4166e-02,\n",
       "          3.7512e-02],\n",
       "         [0.0000e+00, 8.7489e-04, 8.7489e-04,  ..., 1.7498e-03, 0.0000e+00,\n",
       "          1.7498e-03],\n",
       "         [3.0738e-03, 8.1967e-03, 4.9180e-02,  ..., 3.5861e-02, 1.3320e-02,\n",
       "          3.0738e-02],\n",
       "         ...,\n",
       "         [6.9444e-03, 3.8690e-02, 8.9286e-03,  ..., 1.0516e-01, 4.9603e-03,\n",
       "          9.9206e-04],\n",
       "         [5.9406e-03, 2.1782e-02, 1.9802e-03,  ..., 4.9505e-03, 9.9010e-04,\n",
       "          1.9802e-03],\n",
       "         [1.0000e-04, 1.0000e-04, 1.0000e-04,  ..., 1.0000e-04, 1.0000e-04,\n",
       "          1.0000e-04]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.calibrate_top_classes(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
