{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T08:12:19.377444Z",
     "start_time": "2019-10-09T08:12:13.453354Z"
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "\n",
    "from time import time as t\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from bindsnet.network import Network, load\n",
    "from bindsnet.learning import PostPre, WeightDependentPostPre\n",
    "from bindsnet.network.monitors import Monitor, NetworkMonitor\n",
    "from bindsnet.network.nodes import AdaptiveLIFNodes, Input\n",
    "from bindsnet.network.topology import LocalConnection, Connection\n",
    "from bindsnet.analysis.plotting import (\n",
    "    plot_input,\n",
    "    plot_spikes,\n",
    "    plot_conv2d_weights,\n",
    "    plot_voltages,\n",
    "    plot_spikes_display\n",
    ")\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from LC_SNN import LC_SNN\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and encoding MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T07:53:20.586497Z",
     "start_time": "2019-10-09T07:53:20.129132Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "time_max = 30\n",
    "dt = 1\n",
    "intensity = 127.5\n",
    "\n",
    "train_dataset = MNIST(\n",
    "    PoissonEncoder(time=time_max, dt=dt),\n",
    "    None,\n",
    "    \"MNIST\",\n",
    "    download=False,\n",
    "    train=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T07:53:18.684652Z",
     "start_time": "2019-10-09T07:53:14.078312Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters \n",
    "n_filters = 25\n",
    "kernel_size = 12\n",
    "stride = 4 \n",
    "padding = 0\n",
    "conv_size = int((28 - kernel_size + 2 * padding) / stride) + 1\n",
    "per_class = int((n_filters * conv_size * conv_size) / 10)\n",
    "tc_trace = 20.  # grid search check\n",
    "tc_decay = 20.\n",
    "thresh = -52\n",
    "refrac = 5\n",
    "\n",
    "wmin = 0\n",
    "wmax = 1\n",
    "\n",
    "# Network\n",
    "network = Network(learning=True)\n",
    "GlobalMonitor = NetworkMonitor(network, state_vars=('v', 's', 'w'))\n",
    "\n",
    "\n",
    "input_layer = Input(n=784, shape=(1, 28, 28), traces=True)\n",
    "\n",
    "output_layer = AdaptiveLIFNodes(\n",
    "    n=n_filters * conv_size * conv_size,\n",
    "    shape=(n_filters, conv_size, conv_size),\n",
    "    traces=True,\n",
    "    thres=thresh,\n",
    "    trace_tc=tc_trace,\n",
    "    tc_decay=tc_decay,\n",
    "    theta_plus=0.05,\n",
    "    tc_theta_decay=1e6)\n",
    "\n",
    "\n",
    "connection_XY = LocalConnection(\n",
    "    input_layer,\n",
    "    output_layer,\n",
    "    n_filters=n_filters,\n",
    "    kernel_size=kernel_size,\n",
    "    stride=stride,\n",
    "    update_rule=PostPre,\n",
    "    norm=1/2, #1/(kernel_size ** 2),#0.4 * kernel_size ** 2,  # norm constant - check\n",
    "    nu=[1e-4, 1e-2],\n",
    "    wmin=wmin,\n",
    "    wmax=wmax)\n",
    "\n",
    "# competitive connections\n",
    "w = torch.zeros(n_filters, conv_size, conv_size, n_filters, conv_size, conv_size)\n",
    "for fltr1 in range(n_filters):\n",
    "    for fltr2 in range(n_filters):\n",
    "        if fltr1 != fltr2:\n",
    "            # change\n",
    "            for i in range(conv_size):\n",
    "                for j in range(conv_size):\n",
    "                    w[fltr1, i, j, fltr2, i, j] = -100.0\n",
    "                    \n",
    "connection_YY = Connection(output_layer, output_layer, w=w)\n",
    "\n",
    "network.add_layer(input_layer, name='X')\n",
    "network.add_layer(output_layer, name='Y')\n",
    "\n",
    "network.add_connection(connection_XY, source='X', target='Y')\n",
    "network.add_connection(connection_YY, source='Y', target='Y')\n",
    "\n",
    "network.add_monitor(GlobalMonitor, name='Network')\n",
    "\n",
    "spikes = {}\n",
    "for layer in set(network.layers):\n",
    "    spikes[layer] = Monitor(network.layers[layer], state_vars=[\"s\"], time=time_max)\n",
    "    network.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)\n",
    "    print('GlobalMonitor.state_vars:', GlobalMonitor.state_vars)\n",
    "\n",
    "voltages = {}\n",
    "for layer in set(network.layers) - {\"X\"}:\n",
    "    voltages[layer] = Monitor(network.layers[layer], state_vars=[\"v\"], time=time_max)\n",
    "    network.add_monitor(voltages[layer], name=\"%s_voltages\" % layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T07:25:41.843382Z",
     "start_time": "2019-10-07T07:25:41.816599Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize = False\n",
    "n_train = 1\n",
    "for epoch in range(n_train):\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    for batch in tqdm(train_dataloader):\n",
    "        inpts = {\"X\": batch[\"encoded_image\"]}\n",
    "        inpts = {\"X\": batch[\"encoded_image\"].transpose(0, 1)}\n",
    "\n",
    "        network.run(inpts=inpts, time=time_max, input_time_dim=1)\n",
    "    network.reset_()  # Reset state variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T12:57:23.616273Z",
     "start_time": "2019-09-27T12:57:21.973Z"
    }
   },
   "outputs": [],
   "source": [
    "network.save(f'network_{str(datetime.datetime.today())}'[:-7].replace(' ', '_').replace(':', '-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locking network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T12:57:23.618755Z",
     "start_time": "2019-09-27T12:57:21.980Z"
    }
   },
   "outputs": [],
   "source": [
    "network.train(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-27T12:57:23.620747Z",
     "start_time": "2019-09-27T12:57:21.985Z"
    }
   },
   "outputs": [],
   "source": [
    "network = load('default', learning=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T20:49:20.439994Z",
     "start_time": "2019-10-08T20:49:19.192321Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "for whatever, batch in tqdm(list(zip(range(5), test_dataloader))):\n",
    "    cmap = plt.cm.jet\n",
    "    #Processing\n",
    "    inpts = {\"X\": batch[\"encoded_image\"].transpose(0, 1)}\n",
    "    label = batch[\"label\"]\n",
    "    network.run(inpts=inpts, time=time_max, input_time_dim=1)\n",
    "\n",
    "    #Visualization\n",
    "    # Optionally plot various simulation information.\n",
    "    inpt_axes = None\n",
    "    inpt_ims = None\n",
    "    spike_ims = None\n",
    "    spike_axes = None\n",
    "    weights1_im = None\n",
    "    voltage_ims = None\n",
    "    voltage_axes = None\n",
    "    image = batch[\"image\"].view(28, 28)\n",
    "\n",
    "    inpt = inpts[\"X\"].view(time_max, 784).sum(0).view(28, 28)\n",
    "    weights_XY = connection_XY.w\n",
    "    weights_YY = connection_YY.w\n",
    "\n",
    "    _spikes = {\n",
    "        \"X\": spikes[\"X\"].get(\"s\").view(time_max, -1),\n",
    "        \"Y\": spikes[\"Y\"].get(\"s\").view(time_max, -1),\n",
    "    }\n",
    "    _voltages = {\"Y\": voltages[\"Y\"].get(\"v\").view(time_max, -1)}\n",
    "\n",
    "    inpt_axes, inpt_ims = plot_input(\n",
    "        image, inpt, label=label, axes=inpt_axes, ims=inpt_ims\n",
    "    )\n",
    "    spike_ims, spike_axes = plot_spikes_display(_spikes, ims=spike_ims, axes=spike_axes)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 10))\n",
    "    weights_XY = weights_XY.reshape(28, 28, -1)\n",
    "    weights_to_display = torch.zeros(0, 28*25)\n",
    "    i = 0\n",
    "    while i < 625:\n",
    "        for j in range(25):\n",
    "            weights_to_display_row = torch.zeros(28, 0)\n",
    "            for k in range(25):\n",
    "                weights_to_display_row = torch.cat((weights_to_display_row, weights_XY[:, :, i]), dim=1)\n",
    "                i += 1\n",
    "            weights_to_display = torch.cat((weights_to_display, weights_to_display_row), dim=0)\n",
    "    im1 = ax1.imshow(weights_to_display.numpy(), cmap=cmap)\n",
    "    im2 = ax2.imshow(weights_YY.reshape(5*5*25, 5*5*25).numpy(), cmap=cmap)\n",
    "    f.colorbar(im1, ax=ax1)\n",
    "    f.colorbar(im2, ax=ax2)\n",
    "    ax1.set_title('XY weights')\n",
    "    ax2.set_title('YY weights')\n",
    "    f.show()\n",
    "    voltage_ims, voltage_axes = plot_voltages(\n",
    "        _voltages, ims=voltage_ims, axes=voltage_axes\n",
    "    )\n",
    "    \n",
    "network.reset_()  # Reset state variables\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch for best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T00:27:57.188355Z",
     "start_time": "2019-10-09T00:27:52.109929Z"
    }
   },
   "outputs": [],
   "source": [
    "def gridsearch(n_norm=2, n_comp=2, n_iter=100):\n",
    "    norms  = np.linspace(0.1, 0.4, n_norm)\n",
    "    comp_weights = np.linspace(-70, -13, n_comp)\n",
    "    accs = torch.zeros(n_norm, n_comp)\n",
    "    max_acc = 0\n",
    "    best_norm = 0\n",
    "    best_comp_weight = 0\n",
    "    for i, norm in enumerate(norms):\n",
    "        for j, competitive_weight in enumerate(comp_weights):\n",
    "            clear_output(wait=True)\n",
    "            print(f'Current parameters: norm={norm}, comp_weight={competitive_weight}')\n",
    "            net = LC_SNN(norm=norm, competitive_weight=competitive_weight)\n",
    "            net.train(n_iter=n_iter)\n",
    "            net.network.save(f'gridsearch//network_norm={norm}_comp={competitive_weight}_n_iter={n_iter}')\n",
    "            acc = net.accuracy(n_iter)\n",
    "            accs[i, j] = acc\n",
    "            if acc > max_acc:\n",
    "                max_acc = acc\n",
    "                best_norm = norm\n",
    "                best_comp_weght = competitive_weight\n",
    "    torch.save(accs, f'gridsearch//accs_n_norm={n_norm}_n_comp={n_comp}_n_iter=n_iter')\n",
    "    return max_acc, best_norm, competitive_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T00:31:13.246963Z",
     "start_time": "2019-10-09T00:28:22.342289Z"
    }
   },
   "outputs": [],
   "source": [
    "gridsearch(n_norm=5, n_comp=10, n_iter=60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T08:33:44.826947Z",
     "start_time": "2019-10-09T08:33:43.958324Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:48:55.939118Z",
     "start_time": "2019-10-09T09:48:55.929151Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "from LC_SNN import LC_SNN\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "class Wtf:\n",
    "    def __init__(self, norm=1, competitive_weight=1, n_iter=1):\n",
    "        print('initing')\n",
    "    def fit(self, X, y, n_iter):\n",
    "        print('fitting')\n",
    "    def score(self, X, y):\n",
    "        print('predicting')\n",
    "        return np.random.random()\n",
    "    def get_params(self, **args):\n",
    "        return {'norm': 1,\n",
    "                'competitive_weight':1,\n",
    "                'n_iter':1\n",
    "               }\n",
    "    def set_params(self, norm, competitive_weight, n_iter):\n",
    "        return Wtf(norm=norm, competitive_weight=competitive_weight, n_iter=n_iter)\n",
    "    def __repr__(self):\n",
    "        return f'WTF class' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T10:05:22.163146Z",
     "start_time": "2019-10-09T10:05:22.108288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "time_max = 30\n",
    "dt = 1\n",
    "intensity = 127.5\n",
    "\n",
    "train_dataset = MNIST(\n",
    "    PoissonEncoder(time=time_max, dt=dt),\n",
    "    None,\n",
    "    \"MNIST\",\n",
    "    download=False,\n",
    "    train=True,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Lambda(lambda x: x * intensity)]\n",
    "        )\n",
    "    )\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=1, shuffle=True)\n",
    "for batch in test_dataloader:\n",
    "    print(batch['label'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T10:00:16.510189Z",
     "start_time": "2019-10-09T10:00:16.118220Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new(): invalid data type 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-e17f0217547b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_numpy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: new(): invalid data type 'str'"
     ]
    }
   ],
   "source": [
    "data= pd.read_csv('encoded_MNIST.csv', sep='\\t')\n",
    "X_numpy, y_numpy = data['encoded_image'].values, data['label'].values\n",
    "X = []\n",
    "y = []\n",
    "for elem in zip(X_numpy, y_numpy):\n",
    "    X.append(torch.tensor(elem[0]))\n",
    "    y.append(str(elem[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:51:15.251358Z",
     "start_time": "2019-10-09T09:51:12.288246Z"
    }
   },
   "outputs": [],
   "source": [
    "weights = torch.tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:51:29.249389Z",
     "start_time": "2019-10-09T09:51:19.911224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training network...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'transpose'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-4d29271945bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\lab37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\lab37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1469\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\lab37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\lab37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\lab37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\lab37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\lab37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\lab37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\lab37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\lab37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programs\\Anaconda3\\envs\\lab37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Python_Notebooks\\Lab\\Bachelor\\LC_SNN.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, n_iter, plot)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m             \u001b[0minpts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minpts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minpts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_time_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'transpose'"
     ]
    }
   ],
   "source": [
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T10:29:23.178679Z",
     "start_time": "2019-10-09T10:29:23.071293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:35:37.410200Z",
     "start_time": "2019-10-09T09:35:36.909156Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:47:22.458635Z",
     "start_time": "2019-10-09T09:47:18.706473Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T09:47:31.676710Z",
     "start_time": "2019-10-09T09:47:28.401Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
